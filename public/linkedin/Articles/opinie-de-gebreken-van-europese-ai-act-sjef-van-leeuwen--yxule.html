<html>
<head>
  <title>Opinie: De Gebreken van de Europese AI-act</title>
  <style>
    body {
      margin: 0 auto;
      width: 744px;
      font-family: Source Serif Pro, serif;
      line-height: 32px;
      font-weight: 400;
      color: rgba(0, 0, 0, 0.7);
      font-size: 21px;
    }
    h1, h2, h3 {
      font-family: Source Sans Pro, Helvetica, Arial, sans-serif;
    }
    h1 a, h1 a:visited {
      color: inherit;
      text-decoration: none;
    }
    h1 {
      line-height: 48px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 42px;
      margin: 32px 0 20px;
    }
    h2 {
      line-height: 32px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 26px;
      margin: 28px 0;
    }
    h3 {
      line-height: 28px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 21px;
      margin: 24px 0;
    }
    p {
      margin: 32px 0;
    }
    .created, .published {
      color: rgba(0, 0, 0, 0.55);
      font-size: 15px;
      line-height: 15px;
      margin: 20px 0;
    }
    .created + .published {
      margin-top: -12px;
    }
    blockquote {
      font-family: Georgia, Source Serif Pro, serif;
      font-style: italic;
      font-size: 24px;
      line-height: 36px;
      margin: 48px 120px;
      text-align: center;
    }
    a {
      word-wrap: break-word;
      outline: none;
      text-decoration: none;
      background-color: transparent;
      border: 0;
      color: #008CC9;
    }
    a:hover {
      text-decoration: underline;
    }
    a:visited {
      color: #8C68CB;
    }
    .center {
      text-align: center;
    }
    iframe {
      display: block;
      margin: 44px auto;
    }
    *:not(pre) + pre, pre:first-of-type {
      margin-top: 32px;
      padding-top: 32px;
    }
    pre:only-of-type {
      margin: 32px 0;
      padding: 32px;
    }
    pre {
      background: #F3F6F8;
      overflow-x: auto;
      display: block;
      font-size: 13px;
      font-family: monospace;
      line-height: 13px;
      padding: 0 32px 32px;
      white-space: pre;
    }
    a.embedded {
      background: #F3F6F8;
      display: block;
      padding: 32px;
      margin: 32px 0;
    }
    img {
      height: auto;
      max-width: 100%;
    }
    .slate-image-embed__resize-full-width img {
      width: 100%;
    }
    .series-logo {
      width: 48px;
      height: 48px;
      box-sizing: border-box;
      background-clip: content-box;
      border: 4px solid transparent;
      border-radius: 6px;
      object-fit: scale-down;
      float: left;
    }
    .series-title {
      font-size: 16px;
      font-weight: 600;
      vertical-align: top;
    }
    .series-description {
      color: rgba(0,0,0,.6);
      font-weight: 400;
      font-size: 14px;
      line-height: 20px;
    }
    div {
      margin: 32px 0;
    }
  </style>
</head>
<body>
    <img src="https://media.licdn.com/mediaD4E12AQFLEWOjQnzAgQ" alt="" title="" />
      <h1><a href="https://www.linkedin.com/pulse/opinie-de-gebreken-van-europese-ai-act-sjef-van-leeuwen--yxule">Opinie: De Gebreken van de Europese AI-act</a></h1>
    <p class="created">Created on 2024-05-21 15:24</p>
  <p class="published">Published on 2024-05-21 15:35</p>
  <div><p>Vandaag heeft de Europese Raad unaniem ingestemd met de AI-act, een stap die werd gevierd als een mijlpaal in AI-regulering. Staatssecretaris van Koninkrijksrelaties en Digitalisering, <a target="_blank" href="https://www.linkedin.com/in/alexandravanhuffelen?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAQhZLUBAqVRE185wBNDU2G5koOTSN0m1HM">Alexandra van Huffelen</a> , prees de goedkeuring van de wet en benadrukte dat veel Nederlandse voorstellen zijn overgenomen. Ondanks deze optimistische toon, roept de AI-act serieuze vragen op over de daadwerkelijke bescherming van burgerrechten binnen de EU.</p><h3>Gebrek aan Transparantie</h3><p>De AI-act stelt transparantie-eisen aan AI-systemen, maar deze eisen gaan niet ver genoeg. Bedrijven kunnen deze regels gemakkelijk minimalistisch interpreteren of omzeilen. Hierdoor blijven burgers in het duister over hoe hun data wordt gebruikt en welke beslissingen door AI-systemen worden genomen. Transparantie is essentieel, niet alleen voor het vertrouwen van de burger, maar ook voor de verantwoordelijkheid van de bedrijven die deze technologieën ontwikkelen (<a href="https://www.hklaw.com/en/insights/publications/2024/03/the-european-unions-ai-act-what-you-need-to-know" target="_blank">Home | Holland &amp; Knight</a>) (<a href="https://www.skadden.com/insights/publications/2024/02/latest-text-of-eu-ai-act-proposes-expanding-obligation" target="_blank">Skadden, Arps, Slate, Meagher &amp; Flom LLP</a>).</p><h3>Praktische Voorbeelden van Omzeiling</h3><ol><li><p><strong>Vage Begrippen en Termen</strong>: Bedrijven kunnen gebruikmaken van vage of technische taal in hun documentatie om de daadwerkelijke werking van hun AI-systemen te verdoezelen. Dit maakt het moeilijk voor toezichthouders en burgers om te begrijpen wat het systeem precies doet en hoe beslissingen worden genomen.</p></li><li><p><strong>Geheime Algoritmen</strong>: Bedrijven kunnen hun algoritmen als handelsgeheimen beschouwen en weigeren volledige transparantie te bieden onder het voorwendsel van bescherming van intellectueel eigendom. Dit belemmert de mogelijkheid voor onafhankelijke audits en controle op eerlijkheid en bias (<a href="https://www.skadden.com/insights/publications/2024/02/latest-text-of-eu-ai-act-proposes-expanding-obligation" target="_blank">Skadden, Arps, Slate, Meagher &amp; Flom LLP</a>).</p></li></ol><h3>Onvoldoende Bescherming van Mensenrechten</h3><p>Hoewel de act beoogt fundamentele rechten te beschermen, schiet zij tekort in het bieden van robuuste waarborgen tegen schendingen. AI-systemen kunnen diepgaande invloeden hebben op privacy, vrijheid van meningsuiting en non-discriminatie. De huidige wetgeving biedt onvoldoende garanties om te voorkomen dat AI-systemen deze rechten schenden, vooral gezien de mogelijke inzet voor biometrische surveillance en profilering (<a href="https://www.ibm.com/topics/eu-ai-act" target="_blank">IBM - United States</a>) (<a href="https://www.skadden.com/insights/publications/2024/02/latest-text-of-eu-ai-act-proposes-expanding-obligation" target="_blank">Skadden, Arps, Slate, Meagher &amp; Flom LLP</a>).</p><h3>Praktische Voorbeelden van Omzeiling</h3><ol><li><p><strong>Gedeeltelijke Openbaring van Gegevensbronnen</strong>: Bedrijven kunnen slechts gedeeltelijk onthullen welke gegevens ze gebruiken om hun AI-systemen te trainen. Dit maakt het moeilijk om te beoordelen of de data bron vrij is van bias en of de privacy van individuen wordt beschermd.</p></li><li><p><strong>Gebruik van Derde Partijen</strong>: Bedrijven kunnen AI-diensten uitbesteden aan derde partijen in landen met minder strenge regelgeving. Hierdoor kunnen ze de verantwoordelijkheid voor mogelijke schendingen van mensenrechten afschuiven op deze derde partijen, terwijl ze zelf de voordelen van de AI-technologie oogsten (<a href="https://www.skadden.com/insights/publications/2024/02/latest-text-of-eu-ai-act-proposes-expanding-obligation" target="_blank">Skadden, Arps, Slate, Meagher &amp; Flom LLP</a>).</p></li></ol><h3>Risicobeoordeling: Een Subjectieve Aanpak</h3><p>De risicogebaseerde aanpak van de AI-act is problematisch vanwege de subjectiviteit in de categorisatie van AI-systemen. Wat als "hoog risico" wordt beschouwd, kan variëren, waardoor sommige potentieel schadelijke toepassingen mogelijk niet streng genoeg gereguleerd worden. Dit gebrek aan objectiviteit kan leiden tot inconsistente bescherming voor burgers (<a href="https://www.ibm.com/topics/eu-ai-act" target="_blank">IBM - United States</a>) (<a href="https://www.skadden.com/insights/publications/2024/02/latest-text-of-eu-ai-act-proposes-expanding-obligation" target="_blank">Skadden, Arps, Slate, Meagher &amp; Flom LLP</a>).</p><h3>Praktische Voorbeelden van Omzeiling</h3><ol><li><p><strong>Zelfbeoordeling door Bedrijven</strong>: Bedrijven kunnen de risico's van hun eigen AI-systemen beoordelen en daarbij de ernst van de potentiële schade bagatelliseren om minder strenge regels te hoeven volgen.</p></li><li><p><strong>Creatieve Categorisatie</strong>: Bedrijven kunnen AI-toepassingen zodanig hercategoriseren dat ze in een lagere risicoklasse vallen, ook al brengen ze in werkelijkheid aanzienlijke risico's met zich mee. Bijvoorbeeld door een AI-systeem dat gebruikt wordt in de gezondheidszorg (hoog risico) te herdefiniëren als een louter administratief hulpmiddel (laag risico) (<a href="https://www.skadden.com/insights/publications/2024/02/latest-text-of-eu-ai-act-proposes-expanding-obligation" target="_blank">Skadden, Arps, Slate, Meagher &amp; Flom LLP</a>).</p></li></ol><h3>Handhaving: Een Papieren Tijger</h3><p>De handhaving van de AI-act ligt bij nationale autoriteiten, die mogelijk niet de middelen of expertise hebben om effectief toezicht te houden. Zonder robuuste handhaving is de wetgeving niets meer dan een papieren tijger, niet in staat om de burger te beschermen tegen misbruik van AI-technologie (<a href="https://www.skadden.com/insights/publications/2024/02/latest-text-of-eu-ai-act-proposes-expanding-obligation" target="_blank">Skadden, Arps, Slate, Meagher &amp; Flom LLP</a>) (<a href="https://techcrunch.com/2024/02/02/eu-ai-act-coreper-vote/" target="_blank">TechCrunch</a>).</p><h3>Praktische Voorbeelden van Omzeiling</h3><ol><li><p><strong>Gebrek aan Capaciteit bij Toezichthouders</strong>: Nationale toezichthouders kunnen onderbemand en ondergefinancierd zijn, wat leidt tot ineffectieve handhaving en een gebrek aan diepgaande controles op naleving.</p></li><li><p><strong>Regulatory Arbitrage</strong>: Bedrijven kunnen hun activiteiten zodanig structureren dat ze onder de jurisdictie vallen van landen met zwakkere handhavingsmechanismen, waardoor ze strenge regelgeving effectief kunnen ontwijken (<a href="https://techcrunch.com/2024/02/02/eu-ai-act-coreper-vote/" target="_blank">TechCrunch</a>).</p></li></ol><h3>Discriminatie en Bias</h3><p>Een van de grootste zorgen is dat AI-systemen bestaande biases en discriminatie kunnen versterken. De AI-act bevat onvoldoende maatregelen om te garanderen dat AI-systemen eerlijk en onbevooroordeeld zijn. Zonder strikte vereisten voor data governance en bias-mitigatie zijn discriminerende praktijken onvermijdelijk (<a href="https://www.hklaw.com/en/insights/publications/2024/03/the-european-unions-ai-act-what-you-need-to-know" target="_blank">Home | Holland &amp; Knight</a>) (<a href="https://www.ibm.com/topics/eu-ai-act" target="_blank">IBM - United States</a>) (<a href="https://techcrunch.com/2024/02/02/eu-ai-act-coreper-vote/" target="_blank">TechCrunch</a>).</p><h3>Praktische Voorbeelden van Omzeiling</h3><ol><li><p><strong>Selectieve Data Gebruiken</strong>: Bedrijven kunnen selectieve datasets gebruiken die bestaande vooroordelen weerspiegelen en daardoor discriminerende uitkomsten produceren zonder duidelijke regelgeving om dit tegen te gaan.</p></li><li><p><strong>Gebrek aan Onafhankelijke Audits</strong>: Door geen verplichte onafhankelijke audits in te voeren, kunnen bedrijven interne controles uitvoeren die niet kritisch genoeg zijn om discriminatie en bias te identificeren en aan te pakken (<a href="https://www.hklaw.com/en/insights/publications/2024/03/the-european-unions-ai-act-what-you-need-to-know" target="_blank">Home | Holland &amp; Knight</a>).</p></li></ol><h3>Verantwoordingsplicht: Te Vage Routes</h3><p>De verantwoordingsplicht voor bedrijven is in de AI-act onvoldoende uitgewerkt. Burgers moeten duidelijke en toegankelijke routes hebben om juridische stappen te ondernemen tegen bedrijven die schade veroorzaken met hun AI-systemen. De huidige wetgeving biedt dit niet en laat burgers vaak zonder adequate middelen om compensatie te zoeken (<a href="https://www.skadden.com/insights/publications/2024/02/latest-text-of-eu-ai-act-proposes-expanding-obligation" target="_blank">Skadden, Arps, Slate, Meagher &amp; Flom LLP</a>) (<a href="https://techcrunch.com/2024/02/02/eu-ai-act-coreper-vote/" target="_blank">TechCrunch</a>).</p><h3>Praktische Voorbeelden van Omzeiling</h3><ol><li><p><strong>Complexe Klachtenprocedures</strong>: Bedrijven kunnen gebruik maken van complexe en tijdrovende klachtenprocedures die burgers afschrikken om hun rechten te verdedigen.</p></li><li><p><strong>Juridische Doorgangen</strong>: Bedrijven kunnen juridische mazen in de wet benutten om aansprakelijkheid te ontwijken, bijvoorbeeld door contractuele bepalingen die de verantwoordelijkheid beperken of door juridische structuren die het moeilijk maken om hen voor de rechter te brengen (<a href="https://www.skadden.com/insights/publications/2024/02/latest-text-of-eu-ai-act-proposes-expanding-obligation" target="_blank">Skadden, Arps, Slate, Meagher &amp; Flom LLP</a>).</p></li></ol><h3>Reactie van Staatssecretaris <a target="_blank" href="https://www.linkedin.com/in/alexandravanhuffelen?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAQhZLUBAqVRE185wBNDU2G5koOTSN0m1HM">Alexandra van Huffelen</a> </h3><p>Staatssecretaris <a target="_blank" href="https://www.linkedin.com/in/alexandravanhuffelen?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAQhZLUBAqVRE185wBNDU2G5koOTSN0m1HM">Alexandra van Huffelen</a> uitte haar <a href="https://www.linkedin.com/feed/update/urn:li:activity:7198644316557168640?updateEntityUrn=urn%3Ali%3Afs_feedUpdate%3A%28V2%2Curn%3Ali%3Aactivity%3A7198644316557168640%29" target="_blank">tevredenheid over de AI-act</a>, waarbij ze benadrukte dat Nederlandse voorstellen voor meer transparantie, innovatie en verbeterde uitvoeringscapaciteiten zijn opgenomen. Hoewel deze elementen positieve stappen zijn, blijven de hierboven genoemde kritieken relevant en onveranderd. Haar optimisme lijkt de ernstige gebreken in de wetgeving te negeren, die de daadwerkelijke bescherming van burgerrechten ondermijnen.</p><figure><img data-media-urn="urn:li:digitalmediaAsset:D4E12AQG3s6kGi1ssyQ" src="https://media.licdn.com/dms/image/v2/D4E12AQG3s6kGi1ssyQ/article-inline_image-shrink_1500_2232/article-inline_image-shrink_1500_2232/0/1716305390066?e=1769644800&amp;v=beta&amp;t=uJ8tZ4iZTJ9Ctv4AgT1GzWjdrf56UxcwPTi-zQjmin8"><figcaption></figcaption></figure><h3>Conclusie</h3><p>De AI-act van de EU wordt geprezen als een baanbrekende stap in de regulering van kunstmatige intelligentie, maar bij nader inzien blijkt deze wetgeving ernstige tekortkomingen te hebben. Zonder significante verbeteringen zal de act niet in staat zijn om de beloften van bescherming van burgerrechten en mensenrechten na te komen. Het is cruciaal dat de EU deze zorgen adresseert en de wetgeving aanscherpt om ervoor te zorgen dat AI-technologieën echt ten dienste staan van de samenleving, zonder de rechten van individuen te ondermijnen.</p><p>De tijd voor zelfgenoegzaamheid is voorbij. Het is tijd voor een daadkrachtige aanpak die werkelijk de belangen van de burgers beschermt in het tijdperk van kunstmatige intelligentie.</p></div>
</body>
</html>